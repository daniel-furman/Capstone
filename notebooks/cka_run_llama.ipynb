{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am_Ubq6xTaBz"
      },
      "source": [
        "# Run contrastive knowledge assesment notebook for LLaMa 🦙🦙\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/daniel-furman/Capstone/blob/main/notebooks/cka_run_llama.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uccv2X7WeJGv"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41HkTUkbi9p1",
        "outputId": "6ff90aca-43d8-4808-c5d8-bbdbaa577fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4gro-sOZz-O",
        "outputId": "9aa6f7db-d4f7-4825-bf0f-9a9a40130f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Capstone'...\n",
            "remote: Enumerating objects: 388, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 388 (delta 18), reused 34 (delta 12), pack-reused 343\u001b[K\n",
            "Receiving objects: 100% (388/388), 23.65 MiB | 16.05 MiB/s, done.\n",
            "Resolving deltas: 100% (180/180), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/daniel-furman/Capstone.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaXMJaroH_TI",
        "outputId": "507296ee-8f82-486a-d3f9-70326ad58e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Cloning https://github.com/daniel-furman/transformers_llama (to revision llama_push) to /tmp/pip-install-2d8kggwq/transformers_bc428ffd0cd34c5f839894bc55e946bd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/daniel-furman/transformers_llama /tmp/pip-install-2d8kggwq/transformers_bc428ffd0cd34c5f839894bc55e946bd\n",
            "  Resolved https://github.com/daniel-furman/transformers_llama to commit 2a262d782bb687342c9ae102e52894eb7232f768\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.9/dist-packages (from -r /content/Capstone/requirements_llama.txt (line 1)) (1.22.4)\n",
            "Collecting sentencepiece==0.1.97\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/Capstone/requirements_llama.txt (line 3)) (1.13.1+cu116)\n",
            "Collecting accelerate==0.16.0\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.37.0\n",
            "  Downloading bitsandbytes-0.37.0-py3-none-any.whl (76.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r /content/Capstone/requirements_llama.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate==0.16.0->-r /content/Capstone/requirements_llama.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate==0.16.0->-r /content/Capstone/requirements_llama.txt (line 5)) (23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate==0.16.0->-r /content/Capstone/requirements_llama.txt (line 5)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r /content/Capstone/requirements_llama.txt (line 4)) (1.26.14)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.27.0.dev0-py3-none-any.whl size=6688316 sha256=ef397e190673e00c575472e3171e60010f90dab48f93934a1de99fd84ec8fe04\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d52kje1u/wheels/1b/2a/c3/8a5ddf87ee8af113dedfb61c092a7f0ae6d9acf23c8d0481b3\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, bitsandbytes, huggingface-hub, accelerate, transformers\n",
            "Successfully installed accelerate-0.16.0 bitsandbytes-0.37.0 huggingface-hub-0.13.1 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.27.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/Capstone/requirements_llama.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yjnEaRtKd8L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJQImaEDTRMr"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jQTcgbNk-iA"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/Capstone/src/cka_scripts')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6lqNVBmhW-g"
      },
      "source": [
        "## CLI usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D4NDgkf8oAO",
        "outputId": "9e313beb-3384-4a88-bf29-84e36c15098e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-12 07:07:23.159293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-12 07:07:23.337687: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-03-12 07:07:24.170370: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-12 07:07:24.170464: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-12 07:07:24.170485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "CKA for /content/drive/MyDrive/Colab Files/llama/LLaMA/int8/llama-7b/\n",
            "Loading  model...\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "Loading checkpoint shards: 100% 33/33 [05:19<00:00,  9.69s/it]\n",
            "Running comparisons...\n",
            "Done\n",
            "\n",
            "CKA for /content/drive/MyDrive/Colab Files/llama/LLaMA/int8/llama-13b/\n",
            "Loading  model...\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "Loading checkpoint shards: 100% 41/41 [12:41<00:00, 18.56s/it]\n",
            "Running comparisons...\n",
            "Done\n",
            "\n",
            "\n",
            "Score dict full:\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true': 0.71923828125, 'p_false': 0.00710296630859375, 'p_true - p_false': 0.7121353149414062, 'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true': 0.71923828125, 'p_false': 0.00035381317138671875, 'p_true - p_false': 0.7188844680786133, 'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true': 0.71923828125, 'p_false': 0.0004334449768066406, 'p_true - p_false': 0.7188048362731934, 'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true': 0.15966796875, 'p_false': 6.693601608276367e-05, 'p_true - p_false': 0.15960103273391724, 'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true': 0.15966796875, 'p_false': 5.960464477539063e-08, 'p_true - p_false': 0.15966790914535522, 'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true': 0.15966796875, 'p_false': 1.1324882507324219e-06, 'p_true - p_false': 0.15966683626174927, 'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true': 0.7138671875, 'p_false': 0.0004203319549560547, 'p_true - p_false': 0.713446855545044, 'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Oracle']\": {'p_true': 0.7138671875, 'p_false': 1.7464160919189453e-05, 'p_true - p_false': 0.7138497233390808, 'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Intel']\": {'p_true': 0.7138671875, 'p_false': 0.00014638900756835938, 'p_true - p_false': 0.7137207984924316, 'p_true > p_false': 'True'}}], '/content/drive/mydrive/colab files/llama/llama/int8/llama-13b/': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true': 0.5341796875, 'p_false': 0.000965118408203125, 'p_true - p_false': 0.5332145690917969, 'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true': 0.5341796875, 'p_false': 8.612871170043945e-05, 'p_true - p_false': 0.5340935587882996, 'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true': 0.5341796875, 'p_false': 0.0004470348358154297, 'p_true - p_false': 0.5337326526641846, 'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true': 0.27978515625, 'p_false': 1.6033649444580078e-05, 'p_true - p_false': 0.2797691226005554, 'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true': 0.27978515625, 'p_false': 0.0, 'p_true - p_false': 0.27978515625, 'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true': 0.27978515625, 'p_false': 2.980232238769531e-07, 'p_true - p_false': 0.2797848582267761, 'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true': 0.73876953125, 'p_false': 0.0003440380096435547, 'p_true - p_false': 0.7384254932403564, 'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Oracle']\": {'p_true': 0.73876953125, 'p_false': 1.7464160919189453e-05, 'p_true - p_false': 0.7387520670890808, 'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Intel']\": {'p_true': 0.73876953125, 'p_false': 4.076957702636719e-05, 'p_true - p_false': 0.7387287616729736, 'p_true > p_false': 'True'}}]}\n",
            "\n",
            "Score dict succinct:\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Oracle']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Intel']\": {'p_true > p_false': 'True'}}], '/content/drive/mydrive/colab files/llama/llama/int8/llama-13b/': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Oracle']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Intel']\": {'p_true > p_false': 'True'}}]}\n",
            "\n",
            "Score dict summary:\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': 'This model predicted 9/9 facts at a higher prob than the given counterfactual.', '/content/drive/mydrive/colab files/llama/llama/int8/llama-13b/': 'This model predicted 9/9 facts at a higher prob than the given counterfactual.'}\n"
          ]
        }
      ],
      "source": [
        "!python run_cka.py configs.tests.llama_v0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WXwAZfHMgAY"
      },
      "source": [
        "## Notebook usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GVCMUZJXV0mq"
      },
      "outputs": [],
      "source": [
        "from run_cka import main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFy4ijAPc_mS"
      },
      "source": [
        "### gpt2 example with \"verbosity\" turned on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fXTO0xG4Zzx5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fd9ab4cc0669480e96fc76addc41f266",
            "f75fc42920da4153954c5204eb385a05",
            "1225edf24bb14787af067b61afcbffe2",
            "59c907c5f860442b9b2c97fb3b2b4b05",
            "0810ab300d9f47eca128b58773eba223",
            "5dc91425456a44edadeea2283f632efd",
            "98b22a6d5b7746c0a1e8ba41719a30e9",
            "9d66d5a0be76451c9793ea9fc025d544",
            "a0c0146953684e319ad383b895dcdb2b",
            "37a381c78e0d43aa9ba8c9fcca706dcf",
            "1e84687fbcab458e8fb1c6174c1651f7"
          ]
        },
        "outputId": "996b9ded-59a1-4cfc-8165-b53981675bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CKA for /content/drive/MyDrive/Colab Files/llama/LLaMA/int8/llama-7b/\n",
            "Loading  model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd9ab4cc0669480e96fc76addc41f266"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running comparisons...\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Tokyo\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... London\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Tokyo\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Berlin\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Tokyo\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[    1,   450, 29871, 29906, 29900, 29906, 29900, 16373,   892,  4934,\n",
            "           297]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id... Chicago\n",
            "\tmost probable prediction id decoded... Tokyo\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Norm\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Man\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Norm\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Santiago\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Norm\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[    1, 20462,  6811, 29880,   536,  3614,  2058,   297]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id... Bag\n",
            "\tmost probable prediction id decoded... June\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Apple\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Microsoft\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Apple\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Oracle\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Apple\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[    1, 13981, 17163, 29879,   338,   278, 25331,   310]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id... Intel\n",
            "\tmost probable prediction id decoded... Apple\n",
            "\n",
            "Done\n",
            "\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true': 0.71923828125, 'p_false': 0.00710296630859375, 'p_true - p_false': 0.7121353149414062, 'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true': 0.71923828125, 'p_false': 0.00035381317138671875, 'p_true - p_false': 0.7188844680786133, 'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true': 0.71923828125, 'p_false': 0.0004334449768066406, 'p_true - p_false': 0.7188048362731934, 'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true': 0.15966796875, 'p_false': 6.693601608276367e-05, 'p_true - p_false': 0.15960103273391724, 'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true': 0.15966796875, 'p_false': 5.960464477539063e-08, 'p_true - p_false': 0.15966790914535522, 'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true': 0.15966796875, 'p_false': 1.1324882507324219e-06, 'p_true - p_false': 0.15966683626174927, 'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true': 0.7138671875, 'p_false': 0.0004203319549560547, 'p_true - p_false': 0.713446855545044, 'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Oracle']\": {'p_true': 0.7138671875, 'p_false': 1.7464160919189453e-05, 'p_true - p_false': 0.7138497233390808, 'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Intel']\": {'p_true': 0.7138671875, 'p_false': 0.00014638900756835938, 'p_true - p_false': 0.7137207984924316, 'p_true > p_false': 'True'}}]}\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Oracle']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Intel']\": {'p_true > p_false': 'True'}}]}\n",
            "{'/content/drive/mydrive/colab files/llama/llama/int8/llama-7b/': 'This model predicted 9/9 facts at a higher prob than the given counterfactual.'}\n"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    \"models\": [\n",
        "        \"/content/drive/MyDrive/Colab Files/llama/LLaMA/int8/llama-7b/\",\n",
        "    ],\n",
        "    \"input_information\": {\n",
        "        \"0\": {\n",
        "            \"stem\": \"The 2020 Olympics were held in\",\n",
        "            \"true\": \"Tokyo\",\n",
        "            \"false\": [\"London\", \"Berlin\", \"Chicago\"],\n",
        "        },\n",
        "        \"1\": {\n",
        "            \"stem\": \"Operation Overlord took place in\",\n",
        "            \"true\": \"Normandy\",\n",
        "            \"false\": [\"Manila\", \"Santiago\", \"Baghdad\"],\n",
        "        },\n",
        "        \"2\": {\n",
        "            \"stem\": \"Steve Jobs is the founder of\",\n",
        "            \"true\": \"Apple\",\n",
        "            \"false\": [\"Microsoft\", \"Oracle\", \"Intel\"],\n",
        "        },\n",
        "    },\n",
        "    \"verbosity\": True,\n",
        "}\n",
        "\n",
        "score_dicts = main(config)\n",
        "\n",
        "print(score_dicts[0])\n",
        "print(score_dicts[1])\n",
        "print(score_dicts[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AGFcOIO0XU6O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd9ab4cc0669480e96fc76addc41f266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f75fc42920da4153954c5204eb385a05",
              "IPY_MODEL_1225edf24bb14787af067b61afcbffe2",
              "IPY_MODEL_59c907c5f860442b9b2c97fb3b2b4b05"
            ],
            "layout": "IPY_MODEL_0810ab300d9f47eca128b58773eba223"
          }
        },
        "f75fc42920da4153954c5204eb385a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dc91425456a44edadeea2283f632efd",
            "placeholder": "​",
            "style": "IPY_MODEL_98b22a6d5b7746c0a1e8ba41719a30e9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1225edf24bb14787af067b61afcbffe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d66d5a0be76451c9793ea9fc025d544",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0c0146953684e319ad383b895dcdb2b",
            "value": 33
          }
        },
        "59c907c5f860442b9b2c97fb3b2b4b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a381c78e0d43aa9ba8c9fcca706dcf",
            "placeholder": "​",
            "style": "IPY_MODEL_1e84687fbcab458e8fb1c6174c1651f7",
            "value": " 33/33 [01:56&lt;00:00,  3.63s/it]"
          }
        },
        "0810ab300d9f47eca128b58773eba223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dc91425456a44edadeea2283f632efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b22a6d5b7746c0a1e8ba41719a30e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d66d5a0be76451c9793ea9fc025d544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c0146953684e319ad383b895dcdb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37a381c78e0d43aa9ba8c9fcca706dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e84687fbcab458e8fb1c6174c1651f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
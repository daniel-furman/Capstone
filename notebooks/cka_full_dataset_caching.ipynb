{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache calinet probing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/calinet_probing_data_original/probing_data_trex_500each.json', 'r') as f:\n",
    "    data_calinet = json.load(f)\n",
    "    starter_df = pd.DataFrame(list(data_calinet['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter df\n",
    "starter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of these have to do with fact id 1\n",
    "# the sentences are formed in this format...\n",
    "# the start of a factual sentence, involving the subject\n",
    "# and then two possibilities: one true and one false?\n",
    "# storing these, then, we should do something like\n",
    "# sentence stem | correct | incorrect\n",
    "# and we can strip out the <extra_id_x> parts\n",
    "# to keep it model agnostic\n",
    "starter_df['sentences'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create containers to hold our clean data\n",
    "sentence_stems = []\n",
    "correct = []\n",
    "incorrect = []\n",
    "fact_ids = []\n",
    "relations = []\n",
    "subjects = []\n",
    "objects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in starter_df.iterrows():\n",
    "    sentence_list = row['sentences']\n",
    "    for entry in sentence_list:\n",
    "        \n",
    "        # minor cleanup \n",
    "        cleaned_stem = entry[0].replace(\"<extra_id_0>\", \"[BLANK]\").strip()\n",
    "        cleaned_correct = entry[1].replace(\"<extra_id_0>\", \"\").replace(\"<extra_id_1>\", \"\").strip()\n",
    "        cleaned_incorrect = entry[2].replace(\"<extra_id_0>\", \"\").replace(\"<extra_id_1>\", \"\").strip()\n",
    "        \n",
    "        # grab sub<->obj\n",
    "        subjects_and_objects = pd.json_normalize(row['triplet'])\n",
    "        subjects.append(subjects_and_objects.sub_label.values[0])\n",
    "        objects.append(subjects_and_objects.obj_label.values[0])\n",
    "        \n",
    "        # commit \n",
    "        sentence_stems.append(cleaned_stem)\n",
    "        correct.append(cleaned_correct)\n",
    "        incorrect.append(cleaned_incorrect)\n",
    "        fact_ids.append(row['fact_id'])\n",
    "        relations.append(row['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert(len(sentence_stems) ==\n",
    "       len(correct) ==\n",
    "       len(incorrect) ==\n",
    "       len(fact_ids) ==\n",
    "       len(relations) ==\n",
    "      len(subjects) ==\n",
    "      len(objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into big df\n",
    "trex_df = pd.DataFrame({'fact_id': fact_ids,\n",
    "                        'relation': relations, 'subject': subjects,\n",
    "                        'object': objects, 'stem': sentence_stems, 'true': correct,\n",
    "                        'false': incorrect})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full df\n",
    "trex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out initial df\n",
    "trex_df.to_json('../data/calinet_probing_data_original/calinet_trex_full_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put false inputs into a list\n",
    "# with open('../data/calinet_probing_data_original/calinet_trex_full_data.json', 'r') as f:\n",
    "    # data_calinet = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many stems end in [BLANK]? -> 50451, or about 1/3.\n",
    "c = 0\n",
    "for stem in trex_df['stem']:\n",
    "    if stem.endswith(\"[BLANK].\"):\n",
    "        c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_causal_compatibility(stem):\n",
    "    return stem.endswith(\"[BLANK].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_stem(stem):\n",
    "    if stem.endswith(\"[BLANK].\"):\n",
    "        return stem[0: len(stem)-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_causal_df = trex_df[trex_df.apply(lambda x: check_for_causal_compatibility(x.stem), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_causal_df = trex_causal_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_stems = trex_causal_df.apply(lambda x: trim_stem(x.stem), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_causal_df['stem'] = list(trimmed_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}\n",
    "trex_list = trex_causal_df.to_dict('records')\n",
    "for i, entry in enumerate(trex_list):\n",
    "    output_dict[i] = trex_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in output_dict.items():\n",
    "    output_dict[x] = y \n",
    "    output_dict[x]['false'] = [y['false']] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out cleaned/formatted df\n",
    "with open(\n",
    "    f\"../data/calinet_input_information.json\", \"w\"\n",
    ") as outfile:\n",
    "    json.dump(output_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of curiosity, which relation templates persist in the cleaned, 'causal friendly' set...\n",
    "trex_causal_df['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache ROME counterfact data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/rome_counterfact_original/counterfact.json', 'r') as f:\n",
    "    data_rome = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_rome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rome_input_information = {}\n",
    "\n",
    "for i in range(len(data_rome)):\n",
    "    stem = data_rome[i]['requested_rewrite']['prompt'].replace('{}', data_rome[i]['requested_rewrite']['subject'])\n",
    "    \n",
    "    data_rome_input_information[str(i)] = {\n",
    "        \"stem\": stem,\n",
    "        \"true\": data_rome[i]['requested_rewrite']['target_true']['str'],\n",
    "        \"false\": [data_rome[i]['requested_rewrite']['target_new']['str']],\n",
    "        \"case_id\":  data_rome[i]['case_id']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rome_input_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    f\"../data/rome_counterfact_input_information.json\", \"w\"\n",
    ") as outfile:\n",
    "    json.dump(data_rome_input_information, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/calinet_input_information.json', 'r') as f:\n",
    "    data_calinet = json.load(f)\n",
    "\n",
    "with open('../data/rome_counterfact_input_information.json', 'r') as f:\n",
    "    data_rome= json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_calinet\n",
    "#data_rome\n",
    "\n",
    "mixed_itr = 0\n",
    "mixed_df = {}\n",
    "\n",
    "for x, y in data_calinet.items():\n",
    "    y['dataset_original'] = 'calinet_input_information'\n",
    "    mixed_df[str(mixed_itr)] = y\n",
    "\n",
    "    mixed_itr+=1\n",
    "\n",
    "for x, y in data_rome.items():\n",
    "    y['dataset_original'] = 'rome_counterfact_input_information'\n",
    "    mixed_df[str(mixed_itr)] = y\n",
    "    mixed_itr+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrs = 0\n",
    "for x, y in mixed_df.items():\n",
    "    itrs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\n",
    "    f\"../data/calibragpt_full_input_information.json\", \"w\"\n",
    ") as outfile:\n",
    "    json.dump(mixed_df, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "301faebbd5cea7fd4466786a19f1bea9d8baf657aaca95ef39840c46b8697603"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

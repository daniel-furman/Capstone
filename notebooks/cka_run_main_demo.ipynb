{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am_Ubq6xTaBz"
      },
      "source": [
        "# Contrastive knowledge assesment notebook demo\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/daniel-furman/Capstone/blob/main/notebooks/cka_run_main_demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uccv2X7WeJGv"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4gro-sOZz-O",
        "outputId": "ca123107-2f8e-4ae7-bb5c-a4966da88255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Capstone'...\n",
            "remote: Enumerating objects: 507, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 507 (delta 78), reused 130 (delta 48), pack-reused 343\u001b[K\n",
            "Receiving objects: 100% (507/507), 24.35 MiB | 15.88 MiB/s, done.\n",
            "Resolving deltas: 100% (240/240), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/daniel-furman/Capstone.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaXMJaroH_TI",
        "outputId": "0c33a3f0-e4d3-48d5-d3d8-a7a0ade18e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.9/dist-packages (from -r /content/Capstone/requirements.txt (line 1)) (1.22.4)\n",
            "Collecting sentencepiece==0.1.97\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/Capstone/requirements.txt (line 3)) (1.13.1+cu116)\n",
            "Collecting transformers==4.26.1\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.16.0\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.37.0\n",
            "  Downloading bitsandbytes-0.37.0-py3-none-any.whl (76.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r /content/Capstone/requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r /content/Capstone/requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 4)) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 4)) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 4)) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 4)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 4)) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate==0.16.0->-r /content/Capstone/requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.26.1->-r /content/Capstone/requirements.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.26.1->-r /content/Capstone/requirements.txt (line 4)) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.26.1->-r /content/Capstone/requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.26.1->-r /content/Capstone/requirements.txt (line 4)) (1.26.14)\n",
            "Installing collected packages: tokenizers, sentencepiece, bitsandbytes, huggingface-hub, accelerate, transformers\n",
            "Successfully installed accelerate-0.16.0 bitsandbytes-0.37.0 huggingface-hub-0.13.1 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/Capstone/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yjnEaRtKd8L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IJQImaEDTRMr"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0jQTcgbNk-iA"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/Capstone/src/cka_scripts')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WXwAZfHMgAY"
      },
      "source": [
        "## Notebook usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GVCMUZJXV0mq"
      },
      "outputs": [],
      "source": [
        "from run_cka import main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFy4ijAPc_mS"
      },
      "source": [
        "### GPT-J-6B example\n",
        "* The ```config[\"models\"]``` parameter can be changed to any compatible model (see [README](https://github.com/daniel-furman/Capstone#models-tested))\n",
        "    * Models are loaded in int8 via the transformers ```load_in_8bit``` functionality to reduce memory consumption\n",
        "      * Still, memory will be exceeded with larger models. See ```Runtime/Change runtime type``` to upgrade the instance if an OOM error occurs. \n",
        "      * Even with a Premium GPU, Colab is at the moment underpowered to run the larger open-sourced models in the families, such as OPT-66b\n",
        "    * For example, to run a couple different models:\n",
        "```\n",
        "    \"models\": [\n",
        "        \"roberta-base\",\n",
        "        \"google/flan-t5-base\",\n",
        "    ],\n",
        "```\n",
        "* New facts can be input at the ```config[\"input_information\"]``` parameter. These must be input in the same format as the examples. \n",
        "  * For example: to input \"Lebron James is famous for playing the sport of {true: basketball; false\" football}\":\n",
        "\n",
        "        \"3\": {\n",
        "            \"stem\": \"Lebron James is famous for playing the sport of\",\n",
        "            \"true\": \"basketball\",\n",
        "            \"false\": [\"football\"],\n",
        "        },\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXTO0xG4Zzx5",
        "outputId": "ef69a4f8-5414-4c51-a055-0863ade60218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CKA for EleutherAI/gpt-j-6B\n",
            "Loading  model...\n",
            "Running comparisons...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[  464, 12131, 14935,   547,  2714,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id...  Tokyo\n",
            "\tmost probable prediction id decoded...  Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[  464, 12131, 14935,   547,  2714,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id...  London\n",
            "\tmost probable prediction id decoded...  Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[  464, 12131, 14935,   547,  2714,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id...  Tokyo\n",
            "\tmost probable prediction id decoded...  Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[  464, 12131, 14935,   547,  2714,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id...  Berlin\n",
            "\tmost probable prediction id decoded...  Tokyo\n",
            "\n",
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[  464, 12131, 14935,   547,  2714,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id...  Tokyo\n",
            "\tmost probable prediction id decoded...  Tokyo\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 1/4 [00:01<00:04,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tcontext... The 2020 Olympics were held in\n",
            "\ttokenized_context ids... tensor([[  464, 12131, 14935,   547,  2714,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... The 2020 Olympics were held in\n",
            "\tdecoded target id...  Chicago\n",
            "\tmost probable prediction id decoded...  Tokyo\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[32180,  3827, 10572,  1718,  1295,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id...  Normandy\n",
            "\tmost probable prediction id decoded...  the\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[32180,  3827, 10572,  1718,  1295,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id...  Manila\n",
            "\tmost probable prediction id decoded...  the\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[32180,  3827, 10572,  1718,  1295,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id...  Normandy\n",
            "\tmost probable prediction id decoded...  the\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[32180,  3827, 10572,  1718,  1295,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id...  Santiago\n",
            "\tmost probable prediction id decoded...  the\n",
            "\n",
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[32180,  3827, 10572,  1718,  1295,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id...  Normandy\n",
            "\tmost probable prediction id decoded...  the\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 2/4 [00:02<00:02,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tcontext... Operation Overlord took place in\n",
            "\ttokenized_context ids... tensor([[32180,  3827, 10572,  1718,  1295,   287]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Operation Overlord took place in\n",
            "\tdecoded target id...  Baghdad\n",
            "\tmost probable prediction id decoded...  the\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[19206, 19161,   318,   262,  9119,   286]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id...  Apple\n",
            "\tmost probable prediction id decoded...  Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[19206, 19161,   318,   262,  9119,   286]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id...  Microsoft\n",
            "\tmost probable prediction id decoded...  Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[19206, 19161,   318,   262,  9119,   286]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id...  Apple\n",
            "\tmost probable prediction id decoded...  Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[19206, 19161,   318,   262,  9119,   286]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id...  Google\n",
            "\tmost probable prediction id decoded...  Apple\n",
            "\n",
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[19206, 19161,   318,   262,  9119,   286]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id...  Apple\n",
            "\tmost probable prediction id decoded...  Apple\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 3/4 [00:04<00:01,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tcontext... Steve Jobs is the founder of\n",
            "\ttokenized_context ids... tensor([[19206, 19161,   318,   262,  9119,   286]], device='cuda:0')\n",
            "\tdecoded tokenized_context... Steve Jobs is the founder of\n",
            "\tdecoded target id...  Facebook\n",
            "\tmost probable prediction id decoded...  Apple\n",
            "\n",
            "\n",
            "\tcontext... Lebron James is famous for playing the sport of\n",
            "\ttokenized_context ids... tensor([[  43, 1765, 1313, 3700,  318, 5863,  329, 2712,  262, 6332,  286]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Lebron James is famous for playing the sport of\n",
            "\tdecoded target id...  basketball\n",
            "\tmost probable prediction id decoded...  basketball\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:04<00:00,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tcontext... Lebron James is famous for playing the sport of\n",
            "\ttokenized_context ids... tensor([[  43, 1765, 1313, 3700,  318, 5863,  329, 2712,  262, 6332,  286]],\n",
            "       device='cuda:0')\n",
            "\tdecoded tokenized_context... Lebron James is famous for playing the sport of\n",
            "\tdecoded target id...  football\n",
            "\tmost probable prediction id decoded...  basketball\n",
            "\n",
            "Done\n",
            "\n",
            "{'eleutherai/gpt-j-6b': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true': 0.820419192314148, 'p_false': 0.004076048266142607, 'p_true - p_false': 0.8163431440480053, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9950562986708852}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true': 0.820419192314148, 'p_false': 0.00018768371955957264, 'p_true - p_false': 0.8202315085945884, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9997712745009163}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true': 0.820419192314148, 'p_false': 6.958650192245841e-05, 'p_true - p_false': 0.8203496058122255, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9999151767789259}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true': 0.15685658156871796, 'p_false': 8.113250515862092e-09, 'p_true - p_false': 0.15685657345546744, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.999999884523504}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true': 0.15685658156871796, 'p_false': 3.838046325199684e-09, 'p_true - p_false': 0.15685657773067163, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.999999911778996}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true': 0.15685658156871796, 'p_false': 4.956958399304767e-09, 'p_true - p_false': 0.15685657661175956, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9999999046456526}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true': 0.696594774723053, 'p_false': 9.295208292314783e-05, 'p_true - p_false': 0.6965018226401298, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9998665656390776}}, {\"Steve Jobs is the founder of ['Apple', 'Google']\": {'p_true': 0.696594774723053, 'p_false': 0.0004365745116956532, 'p_true - p_false': 0.6961582002113573, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9993736515496591}}, {\"Steve Jobs is the founder of ['Apple', 'Facebook']\": {'p_true': 0.696594774723053, 'p_false': 7.766437192913145e-05, 'p_true - p_false': 0.6965171103511238, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9998885066116364}}, {\"Lebron James is famous for playing the sport of ['basketball', 'football']\": {'p_true': 0.9118819236755371, 'p_false': 0.009742015041410923, 'p_true - p_false': 0.9021399086341262, 'p_true > p_false': 'True', 'p_true / (p_true + p_false)': 0.9894295009857617}}]}\n",
            "{'eleutherai/gpt-j-6b': [{\"The 2020 Olympics were held in ['Tokyo', 'London']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Berlin']\": {'p_true > p_false': 'True'}}, {\"The 2020 Olympics were held in ['Tokyo', 'Chicago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Manila']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Santiago']\": {'p_true > p_false': 'True'}}, {\"Operation Overlord took place in ['Normandy', 'Baghdad']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Microsoft']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Google']\": {'p_true > p_false': 'True'}}, {\"Steve Jobs is the founder of ['Apple', 'Facebook']\": {'p_true > p_false': 'True'}}, {\"Lebron James is famous for playing the sport of ['basketball', 'football']\": {'p_true > p_false': 'True'}}]}\n",
            "{'eleutherai/gpt-j-6b': 'This model predicted 10/10 facts at a higher prob than the given counterfactual. The mean p_true / (p_true + p_false) was 0.9983 while the mean p_true was 0.5933'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    \"models\": [\n",
        "        \"EleutherAI/gpt-j-6B\",\n",
        "\n",
        "        # Example addition(s) of a new model(s)\n",
        "        #\"roberta-base\",\n",
        "        #\"google/flan-t5-base\",\n",
        "\n",
        "    ],\n",
        "    \"input_information\": {\n",
        "        \"0\": {\n",
        "            \"stem\": \"The 2020 Olympics were held in\",\n",
        "            \"true\": \"Tokyo\",\n",
        "            \"false\": [\"London\", \"Berlin\", \"Chicago\"],\n",
        "        },\n",
        "        \"1\": {\n",
        "            \"stem\": \"Operation Overlord took place in\",\n",
        "            \"true\": \"Normandy\",\n",
        "            \"false\": [\"Manila\", \"Santiago\", \"Baghdad\"],\n",
        "        },\n",
        "        \"2\": {\n",
        "            \"stem\": \"Steve Jobs is the founder of\",\n",
        "            \"true\": \"Apple\",\n",
        "            \"false\": [\"Microsoft\", \"Google\", \"Facebook\"],\n",
        "        },\n",
        "\n",
        "        # Example addition(s) of a new fact(s)\n",
        "        \"3\": {\n",
        "            \"stem\": \"Lebron James is famous for playing the sport of\",\n",
        "            \"true\": \"basketball\",\n",
        "            \"false\": [\"football\"],\n",
        "        },\n",
        "    },\n",
        "    \"verbosity\": True,\n",
        "}\n",
        "\n",
        "score_dicts = main(config)\n",
        "\n",
        "print(score_dicts[0])\n",
        "print(score_dicts[1])\n",
        "print(score_dicts[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6lqNVBmhW-g"
      },
      "source": [
        "## CLI usage \n",
        "* Compatible with cached configs included in the repo (see files at ```./content/Capstone/src/cka_scripts/configs``` )\n",
        "* You can also create a custom config for an experiment, see cached configs for the template(s) to build on top of"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hic1I2GZD5BF",
        "outputId": "08e1a4f8-087e-451f-b5dc-b091c144aa5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CKA for distilgpt2\n",
            "Loading  model...\n",
            "Downloading pytorch_model.bin: 100% 353M/353M [00:03<00:00, 102MB/s] \n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "Downloading (…)neration_config.json: 100% 124/124 [00:00<00:00, 45.0kB/s]\n",
            "Running comparisons...\n",
            "100% 21919/21919 [10:21<00:00, 35.26it/s]\n",
            "Done\n",
            "\n",
            "\n",
            "Score dict summary:\n",
            "{'distilgpt2': 'This model predicted 15099/21919 facts at a higher prob than the given counterfactual. The mean p_true / (p_true + p_false) was 0.6568 while the mean p_true was 0.0095'}\n"
          ]
        }
      ],
      "source": [
        "# full benchmark dataset\n",
        "\n",
        "!python run_cka.py configs.rome_full.distilgpt2_rome_full"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nXF0iiYTmlT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}